
<div align="center">
<h2><a href="https://arxiv.org/abs/2505.14679" style="color:#68edcb">UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models</a></h2>
        If our project helps you, please give us a star â­ on GitHub to support us. ğŸ™ğŸ™
        
[![arXiv](https://img.shields.io/badge/arXiv-2505.14679-b31b1b.svg?style=plastic)](https://arxiv.org/abs/2505.14679) 
</div>

## ğŸ”¥ News
* **`2025.05`** ğŸŒŸ We released the paper [UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models](https://arxiv.org/abs/2505.14679).

## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=XiaojieGu/UltraEdit&type=Date)](https://star-history.com/#XiaojieGu/UltraEdit&Date)

## ğŸ“‘ Citation
If you find UltraEdit useful for your research and applications, please cite using this BibTeX:
```bibtex
@misc{Gu2025UltraEdit,
      title={UltraEdit: Training-, Subject-, and Memory-Free Lifelong Editing in Large Language Models}, 
      author={Xiaojie Gu and Guangxu Chen and Jungang Li and Jia-Chen Gu and Xuming Hu and Kai Zhang},
      year={2025},
      eprint={2505.14679},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.14679}, 
}
```
